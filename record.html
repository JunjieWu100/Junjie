<!DOCTYPE html>
<html>
  <head>
    <style>
      /* Style the buttons with equal size and box-like appearance */
      button {
        padding: 15px 30px;
        font-size: 18px;
        margin: 10px;
        cursor: pointer;
        width: 200px; /* Fixed width for uniformity */
        height: 50px; /* Fixed height for uniformity */
        display: block;
        margin-left: auto;
        margin-right: auto;
      }

      /* Center the content */
      body {
        text-align: center;
        font-family: Arial, sans-serif;
      }

      #status {
        font-size: 16px;
        margin-top: 10px;
        display: none; /* Hidden by default */
      }

      /* Style the audio element */
      audio {
        margin-top: 20px;
        width: 100%;
      }
    </style>
  </head>
  <body>
    <h2>Record and Transcribe Audio</h2>

    <!-- Start and Stop buttons for recording -->
    <button id="start">Start Recording</button>
    <button id="stop">Stop Recording</button>

    <!-- Download button (always visible, below Stop and above Audio) -->
    <a id="download" href="#" download="recorded_audio.wav">
      <button>Download Audio</button>
    </a>

    <!-- Audio element for playback (placed below the Download button) -->
    <audio id="audioPlayback" controls></audio>

    <!-- Transcription result -->
    <h3>Transcription:</h3>
    <p id="transcriptionText">Transcription will appear here after recording.</p>

    <script>
      let mediaRecorder;
      let audioChunks = [];

      const startButton = document.getElementById('start');
      const stopButton = document.getElementById('stop');
      const audioPlayback = document.getElementById('audioPlayback');
      const downloadButton = document.getElementById('download');
      const transcriptionText = document.getElementById('transcriptionText');

      // Start recording audio
      startButton.onclick = async () => {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.start();
        audioChunks = [];

        mediaRecorder.ondataavailable = (event) => {
          audioChunks.push(event.data);
        };

        mediaRecorder.onstop = () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
          const audioUrl = URL.createObjectURL(audioBlob);

          // Set the audio for playback
          audioPlayback.src = audioUrl;

          // Update the download button with the new audio URL
          downloadButton.href = audioUrl;

          // Send the audio to AssemblyAI for transcription
          uploadAndTranscribe(audioBlob);
        };
      };

      // Stop recording when the "Stop Recording" button is clicked
      stopButton.onclick = () => {
        mediaRecorder.stop();
      };

      // Function to upload audio and get transcription
      async function uploadAndTranscribe(audioBlob) {
        // Convert the audioBlob to base64
        const reader = new FileReader();
        reader.readAsDataURL(audioBlob);
        reader.onloadend = async () => {
          const base64data = reader.result.split(',')[1]; // Extract base64 portion

          // Upload the audio to AssemblyAI for transcription
          const uploadResponse = await fetch('https://api.assemblyai.com/v2/upload', {
            method: 'POST',
            headers: {
              'authorization': '57468fcab70249bdb924e8288a35166d', // Replace with your AssemblyAI API key
              'content-type': 'application/json',
            },
            body: JSON.stringify({ audio_data: base64data })
          });

          const { upload_url } = await uploadResponse.json();

          // Request transcription from AssemblyAI
          const transcriptionResponse = await fetch('https://api.assemblyai.com/v2/transcript', {
            method: 'POST',
            headers: {
              'authorization': '57468fcab70249bdb924e8288a35166d', // Replace with your AssemblyAI API key
              'content-type': 'application/json',
            },
            body: JSON.stringify({ audio_url: upload_url })
          });

          const transcriptionData = await transcriptionResponse.json();

          // Poll for transcription completion
          let transcriptionStatus = transcriptionData.status;
          while (transcriptionStatus !== 'completed') {
            const statusResponse = await fetch(`https://api.assemblyai.com/v2/transcript/${transcriptionData.id}`, {
              method: 'GET',
              headers: {
                'authorization': '57468fcab70249bdb924e8288a35166d', // Replace with your AssemblyAI API key
              },
            });
            const statusData = await statusResponse.json();
            transcriptionStatus = statusData.status;

            if (transcriptionStatus === 'completed') {
              transcriptionText.innerText = statusData.text; // Display transcription
            }

            await new Promise(resolve => setTimeout(resolve, 3000)); // Wait 3 seconds before checking again
          }
        };
      }
    </script>
  </body>
</html>
